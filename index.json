[{"content":"Program 1: Parallel Fractal Generation Using Threads(20 points) 1.研究加速比与线程关系 研究加速比与线程关系。加速比与使用的线程数成线性关系吗？在您的文章中假设为什么是（或不是）这种情况？\n与基准的串行生成效率相比，在不同线程数下生成不同Mandelbrot图的加速比结果如下图所示。\n可以看到对于view1图来说，加速比与使用的线程数并不成线性相关，甚至3线程的时间比2线程的时间更长。而对于view2图来说，加速比与使用的线程数近似成线性相关。\n可能的原因是因为线程根据块进行划分工作区域，而各个区域之间的工作负载并不平衡。导致最终需要的时间会取决于工作量最大的线程锁消耗的时间。因为观察view1可以发现，中间区域亮的部分更多，说明所需要的计算更多，而上下边缘亮部区域较小。\n而对于view2，他整个图片的上下不同区域的亮度近似，计算量近似。所以加速比随线程增加而线性增加。\n2. 验证假设 通过在调用workerThreadStart()函数的开头和结尾加上计时代码，得到如下结果。对于view1的生成过程，当使用2个线程时，每个线程都需要接近150多ms的时间来完成计算，所以最后的加速比约为1.9x，接近2x。\n而在使用3个线程时，可以发现线程1即中间那个线程，计算时间特别长，需要185ms左右的时间才能够完成计算。而其前后两个线程都只需要62ms左右的时间即可完成。所以总的计算时长由线程1决定。\n证明是工作负载不平衡导致的加速比无法接近预期结果。\n3.修改工作到线程的映射 以实现在 Mandelbrot 集的两个视图上将加速提高到大约 7-8 倍\n因为要求提到要使用静态分配的方法解决这一问题，所以可以让每个线程交替执行一行，将块划分变为按行交替划分。即第i个线程执行第i+num*k行，其中i为线程号（从0开始），num为总的线程数量，k为大于等于0的整数。\n最后我在view1和view2上得到的加速比分别为6.59和6.3。\n对于加速比未达到7-8，我一开始猜想可能是因为我没有改动mandelbrotSerial()函数，选择在workerThreadStart()中通过多次调用mandelbrotSerial()函数的方式进行计算。每行调用一次函数的开销导致了性能下降。后续我改为了每个线程每次计算n行（n=1,2,4,8），减小了总的函数调用次数，但加速比仍然没有太大变化。猜测可能是和机器有关。因为静态分配应该是按行进行分配的。\n4.翻倍线程数 现在用 16 个线程运行改进后的代码。性能是否明显高于运行八个线程时的性能？为什么或者为什么不？\n因为我用的机器是i7-12700h，有6个性能核心和8个效率核心，而6个性能核心各自搭载了intel的超线程技术，所以理论上总的线程数为6*2+8=20线程。所以测试已修改过映射关系的并行代码在20线程和40线程上的结果。\n在view1上，20线程的加速比为12.95x，40线程的加速比为13.27x.在view2上，20线程的加速比为12.19x,40线程的加速比为12.09x。可以看到，20线程和40线程无明显性能优劣，甚至基本持平。 我的猜测是，20线程是系统能够同时工作而不切换线程上下文的最大线程数。能够实际同时工作的最大线程数就是20，而40线程实际上是多了线程之间的上下文的切换，每个时钟周期的计算量和20线程基本相同。所以两者的加速比基本持平。\nProgram 2: Vectrorizing Code Using SIMD Intrinsics (20 points) 1. 矢量利用率的变化 矢量利用率是随着VECTOR_WIDTH变化而增加、减少还是保持不变？为什么？\n首先查看代码可以发现，指数为0的数据占总数据的比例较少，所以当VECTOR_WIDTH增加的时候，会有更多的同组的数据运行y==0这部分的代码，导致一定的矢量利用率的下降。\n另外，同一批数据进行矢量乘法的次数取决于这批数据中最大的指数的值。所以当VECTOR_WIDTH增加时，虽然总的指令数减少了，但同组数据进行无效的被屏蔽的乘法的次数也会增加。\n所以综上所述，矢量利用率随着VECTOR_WIDTH的增加，矢量利用率会下降。\nVECTOR_WIDTH the vector utilization 2 76.90% 4 69.70% 8 65.90% 16 64.20% Program 3, Part 2: ISPC Tasks (10 of 20 points) 1.SIMD期望加速比 编译运行ispc编译器产生的程序，此时期望的加速比是多少？为什么观察到的数字小于这个理想值？\n我期望的加速比为8.但实际得到的加速比约为3.5x左右。我觉得这是因为图片view1中会存在一些处于黑白边界的值，或者同样的8位值其白色程度不同，反映了不同的计算迭代次数。但因为使用了SIMD，所以会有无效的迭代计算操作。\n这个可以通过view2图来间接证明。观察view2图可以发现，view2图整体颜色分布较为平均，黑白相间的区域更多，因此理论上加速比更慢。通过实际测试得到也可以发现确实如此，在view2上加速比约为2.8x左右。\nProgram 3, Part 2: ISPC Tasks (10 of 20 points) 1.tasks期望加速比 mandelbrot_ispc带参数运行--tasks。您在视图 1 上观察到什么加速？mandelbrot_ispc与不将计算划分为任务的版本相比，加速是多少？\n在view 1上观察到的加速比为6.81x。相比不划分任务，加速为1.94x。接近2x的预期提升。\n2.优化tasks性能 通过仅更改函数中的代码 mandelbrot_ispc_withtasks()，您应该能够获得超过顺序版本代码 32 倍以上的性能！您如何确定要创建多少任务？为什么您选择的数字效果最好？\n我通过测试发现，将8行计算任务划分为单个的task，能够达到37.76x的加速比。\n我测试了2,4,8……height个不同的任务个数，当任务个数太少时，容易产生负载不均衡的现象，总体时间受到最慢的任务的拖累。当每个任务仅为1行时，虽然能够得到接近30x加速比的结果，但可能由于每个任务过小，任务的切换上需要耗费一定的时间。\n后续测试了每个任务2,4,8行，在8行时能够得到37.76x的效果。我想是因为这样既保证了任务的细颗粒度地划分，保证负载较为均匀的分配，又保证了较少的任务切换的过程。\nProgram 4: Iterative sqrt (15 points) 1.ISPC加速比 构建并运行sqrt。报告单 CPU 内核（无任务）和使用所有内核（有任务）时的 ISPC 实现加速。SIMD 并行化带来的加速是多少？多核并行化带来的加速是多少？\nSIMD并行化带来的加速是3.64x,多核并行化带来的加速是47.71x,相比SIMD的加速比是13.01x。\n2.构造最优输入 构造一个特定的输入，使代码的顺序版本的加速最大化，并报告所实现的最终加速（对于有任务和无任务 ISPC 实现）。您的修改是否提高了 SIMD 加速？它是否提高了多核加速（即从无任务的 ISPC 转移到有任务的 ISPC 的好处）？请解释原因。\n我构造的特定输入为所有value[i]都为2.999。这样可以保证计算需要的时间和每次使用SIMD操作时没有多余的掩膜计算操作的浪费，能够最大程度地展示SIMD的并行优势，和多核加速的优势。 最终SIMD并行化带来的加速是4.38x,多核并行化带来的加速是54.20x,相比SIMD的加速比是12.37x。\n3.构造最坏输入 构造一个特定的输入，使sqrtISPC （无任务）在代码的顺序版本上的加速最小化。描述这个输入，描述你选择它的原因，并报告 ISPC 实现的结果相对性能。效率损失的原因是什么？\n我构造的特定输入为所有整除8余数为0的i的value[i]的值为2.999，其余为1.这样就保证了一组8个数中，有7个数只需要1次迭代，而因为存在2.999,所有的1需要迭代和2.999一样的次数，导致性能大幅下降。\n最终SIMD并行化带来的加速是0.61x,多核并行化带来的加速是7.01x,相比SIMD的加速比是11.49x。 Program 5: BLAS saxpy (10 points) 1.ISPC加速比 编译运行saxpy。该程序将报告 ISPC（无任务）和 ISPC（有任务）实施 saxpy 的性能。您观察到在任务中使用 ISPC 有什么加速？解释这个程序的性能。你认为它可以得到实质性的改善吗？\n我观察到使用使用了task的ISPC和不使用task的ISPC程序所需要的时间几乎相等，加速比为1.14x。\n通过观察总的内存带宽，我觉得这一性能问题是由于内存带宽的限制引起的。可能是因为程序计算内容较为简单，时间性能瓶颈存在于内存的读取上，导致即使使用多核并行计算，但仍然是通过总线读取内存，受限于总线的带宽。\n为了测试验证这一问题，我将N的值x5,观察结果可以发现，内存的读取速度几乎没有变化，可以验证上述的结论。\n2.带宽计算公式 请注意main.cpp中计算消耗的总内存带宽的公式为TOTAL_BYTES = 4 * N * sizeof(float);。即使saxpy从 X 加载一个元素，从 Y 加载一个元素，并将一个元素写入result，乘数 4 也是正确的。为什么会这样？\n因为读取这一操作需要一次内存加载操作，而给result[i]赋值这一操作是一次修改操作。涉及内存的load和store，需要两次内存操作。所以总的操作次数为4.\n","permalink":"https://haveanapplepie.github.io/posts/tech/cmu15418-assignment1/","summary":"Program 1: Parallel Fractal Generation Using Threads(20 points) 1.研究加速比与线程关系 研究加速比与线程关系。加速比与使用的线程数成线性关系吗？在您的文章中假设为什么是（或不是）这种情况？","title":"CMU15418 Assignment1"},{"content":"前言 这篇博客主要是关于CMU15-213课程的CacheLab中的Part B实验的个人优化方案介绍。博客中不涉及具体的代码，具体代码请查看该课程对应的个人GitHub仓库地址github.com/HaveAnApplePie/CMU-15213-Lab\nPartB 题目 Part B的要求是写一个矩阵转置函数void transpose_submit(int M, int N, int A[N][M], int B[M][N])实现矩阵A到矩阵B的转置，尽可能地减小cache中的miss次数。\n测试三种矩阵规模：32 x 32, 64 x 64, 61 x 67. 满分的要求为：\n32 x 32: miss number \u0026lt; 300\n64 x 64: miss number \u0026lt; 1300\n61 x 67: miss number \u0026lt; 2000\n针对这三种情况，可以对每种情况进行特定优化，而其余情况只需要保证准确性即可。（更详细要求请查看实验的Writeup）\n基础思想：使用Blocking对矩阵进行分块，从而减小对同一块内存区域的访问次数，减少miss数。\nCache 配置 实验给出的Cache配置为（s = 5, E = 1, b = 5），是一个直接相连的Cache。Set个数为32，每个Set中Line的个数为1，每个Line中Block的大小为32bytes。\n32 x 32 最优情况 $2*32*32/8=256$\n解题过程 针对32x32的情况，首先分析块的大小。每一行有32个int，而每一个Block（指Cache中的Block）可以存储8个int，因此每一行用4个block进行存储。如下图所示，对于整个32x32的矩阵，需要的Cache的Block数为$3232/(832)=4$.因此读取一个32x32的矩阵到Cache中总共会写满Cache4次，每写8行会填满一次Cache，即第1行和第9行会发生conflict miss。\n所以使用Blocking的size为8。但此时测试发现，总的miss次数在330多，离最优情况仍有较大距离。之后通过对A矩阵和B矩阵的地址输出会发现，A,B矩阵相同i,j位置的元素会映射到Cache的同一个Block中，所以在对角线块的转置过程中会发生严重的conflict miss，从而导致miss次数大幅上升。\n具体的过程可以看下面这张示意图，图中模拟了A,B两个3x3的矩阵，两者相同i,j位置的元素会映射到Cache的同一个Line中。Cache中总共有3个Line，每一个Line保存对应行号的内存，如Line1可以保存A矩阵的第一行3个值，或是B矩阵第一行的三个值。A,B矩阵中的数字代表了对着9个元素的读取顺序，高亮强调的表示出现miss，同时每个Line下面的字母代表了保存的是A还是B中的对应内存。\n最终我们可以发现，因为conflict miss的存在，19个元素的读取过程中发生了总共12次miss。\n为了解决这一问题，在不用新建临时变量的情况下，可以使用在读取每一行时最后读取对角线元素的方法，而这就规避了频繁的conflict miss的出现。在A读完该行元素之后，B在覆盖对应行的cache。最终，整体的miss数减小到了8，较为接近理想的6次miss的情况。\n使用这种方法可以将miss个数控制在300以内，符合题目要求。\n64 x 64 这是整个cache实验最难的部分，需要用到临时变量来存值。\n最优情况 $2*64*64/8=1024$\n解题过程 一开始的解题思路和32x32相似，计算应该使用的块的大小。通过计算可以知道对于64x64的矩阵，读入的过程中会发生16次填满Cache的过程。所以块纵轴方向的大小应该为4，而横轴方向还应该为8，因为一个block可以包含8个int。然而因为是计算矩阵的转置，转置之后从4x8变成了8x4，依旧会在B矩阵处造成多次conflict miss。所以还是选用更小的4作为块的大小。\n经过测试之后，使用4x4块的总miss次数为1651，离1300还有一定的距离，需要进行进一步更细致的优化。因此后续分析具体的过程。\n在后续分析的过程中，首先定义分析的块的大小为8x8，内部分为4个4x4的块进行分析。因为每个block可以保存8个int，所以使用8进行分析更为简单。所以64x64的矩阵被分为64个8x8的矩阵，其中在对角线上的矩阵有8个，不在对角线上的矩阵有56个。下面详细分析每种矩阵的miss数。\n对角线上的矩阵\n如下图所示，我们将A和B两个矩阵各自划分为4个小块，每个小块为4x4的矩阵，且每个小块内部不会发生conflict miss。\nStep1:将A1转置到B1，这一步使用我们在32x32问题中用到的技巧（每一行最后访问对角线元素），可以算出总的miss为11.此时Cache中保存的为B矩阵的B内存（B1和B2）。 Step2:将C1转置到B2，这一步总共需要8次miss。 这里有一个小的trick，关于转置完A1之后是应该访问A2还是C1。可以看到，如果访问A2，其转置的结果是D2，C1转置的结果是B2。而经过A1转置B1之后，cache中保存的位B矩阵的B内存，所以选择C1可以减小3次conflic miss，最大程度上利用B内存。\nStep3:对A2和C2重复相同步骤，其步骤和Step1和Step2是完全等价的。 所以针对对角线上的矩阵，其总的miss数为$2*(11+8)=38$. 不在对角线的矩阵\n因为矩阵不在对角线上，所以观察示意图可以发现，A矩阵和B矩阵会被映射到不同的Set上，不会发生conflic miss。只有矩阵A,B内部会发生conflict miss，如A1，A2和C1，C2.\nStep1:将A1转置到B1，主要是每个部分自己的4行数据的读取，总共是4+4=8miss。此时Cache中为A(A1,A2)和B(B1,B2)。 Step2:将C1转置到B2，读取C1的过程中会发生4次conflict miss。 Step3:重复Step1和Step2的过程。 所以针对不在对角线上的矩阵，其总的miss数为$2*(8+4)=24$.\n至此我们可以计算我们理论的miss数：$8*38+56*24=1648$.而离测试数据1651还有3个miss的误差可能是因为除矩阵外的其他内存的存取，这个可以在导出的tracef0文件中进行查看。总体来说是符合当前结果的。\n因为，我们的下一步可以选择优化对角线矩阵或者不在对角线上的矩阵使得我们的结果最终能小于1300miss的要求。考虑到不在对角线上的矩阵个数更多，有56个，因此选择优化不在对角线上的矩阵。其理论上的最小的miss次数是$8+8=16$。如果我们能优化到16，那么最后的miss次数为$1651-(24-16)*56=1203$，就能够符合要求。\n在最优情况下，我们希望A,B,C,D内存中的每行只加载一次。当A1转置为B1时，之前我们接下来选择C1转置为B2，而这时A2的数据还没有被保存，在之后的访问中造成了不必要的miss。为了消除这种情况，我们可以将在A1转置为B1的过程中，将A2的数据先保存在B2处。通过这种方法，我们就能保证对A内存区域只加载一次。之后再进行C1和B2的转换，但在这过程中因为题目中对临时变量个数的限制，我们需要选择合适的方法，在这过程中同样把B2中之前保存的A2数据给填充到D2里。最后进行C2和D2的转换。\n下面是具体的操作步骤\nStep1:将A1转置到B1.按列读取A1中的数据，在第一次加载第一列的时候会发生4次miss。在每次读取的过程中，将A2中对应列的数据保存在临时变量a0,a1,a2,a3中，再保存到B2对应的行上。在完成了A1到B1的转置之后，也完成了A2到B2的数据保存。总共发生了8次miss。 Step2:①和②读取B2的第一行，将其值保存在临时变量a0,a1,a2,a3中。③按列读取C1处的第一列，此时发生4次miss。④将C1处的第一列保存到B2的第一行中。此时B内存的第一行都已经得到了正确的值，可以在之后被替换了。⑤将Cache中的B内存的第一行替换为D内存的第一行，发生1次miss。并且将临时变量a0,a1,a2,a3中的值填充到D1的第一行，完成赋值。⑥重复1-5步骤，完成四行的填充。此时完成了A2到D1，C1到B2的转置。总共发生了$4+1+1+1+1=8$次miss。 Step3:此时Cache中为C内存和D内存，完成最后的C2到D2的转置，此时不会发生miss。 所以此时不在对角线上的块的总的miss次数为理想情况的16次。此时的miss次数为$38*8+16*56=1200$。实际测试结果为1203，符合理论情况。\n61 x 67 因为不规则，所以即使按块进行划分，还是会渐渐出现一个块中的元素属于不同的block的情况。这里主要的算法思路是先大段继续分块，然后剩余的部分使用最简单的转置。\n在做这道题的时候，我主要尝试了不同的block大小，最后发现好像和8有公因数的块大小都能取得较为不错的效果。如8,6,12,16等。而12又比8有着更好的效果，猜测可能是因为cache更大一些，能够解决更多的一个块中的元素属于不同的block的情况。最终我选择了12，它符合总miss数小于2000的要求。\n","permalink":"https://haveanapplepie.github.io/posts/tech/cmu15213-cachelab/","summary":"前言 这篇博客主要是关于CMU15-213课程的CacheLab中的Part B实验的个人优化方案介绍。博客中不涉及具体的代码，具体代码请查看该","title":"CMU15213 CacheLab"},{"content":"前几天师兄找我帮他改一下组内的一个python自动化工具的命令行交互界面，主要是美观一下界面，并且加上一些常用的功能，如自动补全等。因为之前没有相关的经验，所以搜索了相关资料，发现有一个叫做prompt_toolkit的python库非常适合便捷地实现这些功能，所以便依据相关博客和官方文档逐步实现相关的需求。本身这个库是用于开发复杂的命令行交互的，我只使用了其中很小的一部分功能。\n1 pip install prompt_toolkit 接收输入 根据官方文档，除了调用prompt()函数外，还可以通过创建一个PromptSession()实例，然后用prompt()对其进行调用。\n我选择了后面这一方法，主要因为：\n输入的历史记录会在prompt()之间保留，从而可以便于后面在内存中的历史命令储存。 可以在一个实例中的多个prompt()间传递后面实现多个功能所需的参数，而且可以通过值传递来进行覆盖，如判断密码输入 其中，prompt()的第一个参数是输入提示，此处设为\u0026gt;\u0026gt;\u0026gt; 。简单的echo程序如下。\n1 2 3 4 5 6 7 8 from prompt_toolkit import PromptSession # 创建实例 session = PromptSession() # 获得输入 user_input = session.prompt(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;) print(\u0026#39;You said: %s\u0026#39; % user_input) 命令历史 通过prompt库添加命令历史很简单，主要有储存在内存中的InMemoryHistory和储存在磁盘文件中的FileHistory两种模式。如果要使用保存到磁盘中的模式需要指定一个文件，可以是dot文件，也可以是txt文件，但因为考虑到交互界面里有要输入密码的情况，处于安全考虑，我直接使用了InMemoryHistory来进行储存历史，每次关闭都会清空。而如果使用前面的PromptSession来获得输入，命令历史的功能是默认开启的，所以代码和上面的示例一样。\n然后可以通过上下箭头来快速获得之前输入的命令。\n自动建议 自动建议是将根据历史命令向用户提供输入建议，补全将显示未当前输入后的灰色文本。这个历史默认匹配的是最近的一条命令，通过右键→、或^e(ctrl+e)实现补全，alt+f将插入第一个单词，可以多次使用。使用PromptSession时可以在多个prompt()会话之间传递命令历史和自动建议。\n1 2 3 4 5 6 7 8 9 10 from prompt_toolkit import PromptSession from prompt_toolkit.history import InMemoryHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory # 创建实例 session = PromptSession() # 获得输入 user_input = session.prompt(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;, auto_suggest=AutoSuggestFromHistory()) print(\u0026#39;You said: %s\u0026#39; % user_input) 自动补全 自动补全是对于常用的关键字，如SQL中常见的关键字或程序中常见的关键字进行补全。可以通过传递completer参数来实现这一功能。\n但自动补全在用的时候我发现有一个问题，就是开启了自动补全后命令行界面每句新的提示都会强制居中，反映到感观中就是会滚动一下，暂时不知道是由什么因素引起的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from prompt_toolkit import PromptSession from prompt_toolkit.history import InMemoryHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.completion import WordCompleter # 创建实例 session = PromptSession() boxCompleter = WordCompleter([\u0026#39;help\u0026#39;,\u0026#39;show\u0026#39;,\u0026#39;set\u0026#39;,\u0026#39;download\u0026#39;]) # 获得输入 user_input = session.prompt(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;, auto_suggest=AutoSuggestFromHistory(), completer=boxCmpleter_completer) print(\u0026#39;You said: %s\u0026#39; % user_input) 格式化文字 在官方文档中有多种实现格式化文字的方式，我选择了其中的HTML进行实现。先建立样式表Style.from_dict中的类，然后可以在HTML中使用自定义的标记样式。\n1 2 3 4 5 6 7 8 9 10 11 #样式 our_style = Style.from_dict({ #log \u0026#39;infosty\u0026#39;:\u0026#39;ansicyan\u0026#39;, \u0026#39;warningsty\u0026#39;:\u0026#39;ansibrightyellow\u0026#39;, \u0026#39;errorsty\u0026#39;:\u0026#39;ansibrightred\u0026#39;, #logo \u0026#39;logosty\u0026#39;:\u0026#39;ansibrightcyan\u0026#39;, #boxprompt \u0026#39;symbol\u0026#39;: \u0026#39;ansibrightyellow\u0026#39;, }) 以错误输入为例\n1 2 3 4 def printBadCmd(): print(\u0026#34;\u0026#34;) print_formatted_text(HTML(\u0026#39;\u0026lt;errorsty\u0026gt;指令有误\u0026lt;/errorsty\u0026gt;\u0026#39;),style=our_style) print(\u0026#34;\u0026#34;) 前面图片中的提示符\u0026gt;\u0026gt;\u0026gt;也是有颜色的，也是通过类似的代码实现。\n1 2 3 4 5 6 #prompt格式 boxPrompt = [(\u0026#39;class:symbol\u0026#39;,\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;)] user_input = session.prompt(boxPrompt, auto_suggest=AutoSuggestFromHistory(), completer=boxCmpleter_completer, style=our_style) 更多的颜色在官方文档中有记录\n密码输入 需求是在密码输入时输入的内容加密为*号，通过把prompt()参数中的is_password置为True来实现。特别需要注意的是，因为在PromptSession的prompt()函数中参数是共享传递的，所以如果在输入密码的case中使用了is_password为True的话，需要在别的地方都加上这个参数并且把它置为False，不然之后的输入也会都变成*号。\n此处可能前两个参数也不需要，只要is_password即可。\n1 2 3 newpassword = session.prompt(boxPrompt, style=our_style, is_password=True) logo制作 通过对应的网址获得想要的logo的样式版本，可以通过print注释的方式显示，也可以通过之前的HTML对其进行赋色等操作。其中特别要注意的是HTML中的\u0026lt;和\u0026gt;都是预留字符，需要替换为字符实体。\n1 2 3 4 5 6 7 8 9 10 def printLogoVersion(): #logo print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt; __ __.__ __________ \u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt;/ \\ / \\ |__ ____\\______ \\ _______ ___\u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt;\\ \\/\\/ / | \\ / _ \\| | _// _ \\ \\/ /\u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt; \\ /| Y ( \u0026lt;_\u0026gt; ) | ( \u0026lt;_\u0026gt; \u0026gt; \u0026lt; \u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt; \\__/\\ / |___| /\\____/|______ /\\____/__/\\_ \\\u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt; \\/ \\/ \\/ \\/\u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) #version print_formatted_text(HTML(\u0026#39;\u0026lt;logosty\u0026gt;version: 0.0.1\u0026lt;/logosty\u0026gt;\u0026#39;),style=our_style) 总结 通过Prompt这个库，基本上能够较为快速地使用python实现基础的命令行交互的功能。网上关于这个库的中文资料较少，大部分还是要看官方文档，不过官方文档非常详细。\n参考资料 4 个用于构建优秀的命令行用户界面的 Python 库\nPrompt官方文档\nPython 交互式命令行应用\nlogo样式网站\n","permalink":"https://haveanapplepie.github.io/posts/tech/python%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BA%A4%E4%BA%92%E5%BA%93prompt/","summary":"前几天师兄找我帮他改一下组内的一个python自动化工具的命令行交互界面，主要是美观一下界面，并且加上一些常用的功能，如自动补全等。因为之前","title":"Python命令行交互库Prompt"}]