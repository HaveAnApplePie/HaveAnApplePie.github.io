[{"content":"前言 这篇博客主要是关于CMU15-213课程的CacheLab中的Part B实验的个人优化方案介绍。博客中不涉及具体的代码，具体代码请查看该课程对应的个人GitHub仓库地址github.com/HaveAnApplePie/CMU-15213-Lab\nPartB 题目 Part B的要求是写一个矩阵转置函数void transpose_submit(int M, int N, int A[N][M], int B[M][N])实现矩阵A到矩阵B的转置，尽可能地减小cache中的miss次数。 测试三种矩阵规模：32 x 32, 64 x 64, 61 x 67. 满分的要求为：\n32 x 32: miss number \u0026lt; 300\n64 x 64: miss number \u0026lt; 1300\n61 x 67: miss number \u0026lt; 2000 针对这三种情况，可以对每种情况进行特定优化，而其余情况只需要保证准确性即可。（更详细要求请查看实验的Writeup）\n基础思想：使用Blocking对矩阵进行分块，从而减小对同一块内存区域的访问次数，减少miss数。\nCache 配置 实验给出的Cache配置为（s = 5, E = 1, b = 5），是一个直接相连的Cache。Set个数为32，每个Set中Line的个数为1，每个Line中Block的大小为32bytes。\n32 x 32 最优情况 $23232/8=256$\n解题过程 针对32x32的情况，首先分析块的大小。每一行有32个int，而每一个Block（指Cache中的Block）可以存储8个int，因此每一行用4个block进行存储。如下图所示，对于整个32x32的矩阵，需要的Cache的Block数为$3232/(832)=4$.因此读取一个32x32的矩阵到Cache中总共会写满Cache4次，每写8行会填满一次Cache，即第1行和第9行会发生conflict miss。\n所以使用Blocking的size为8。但此时测试发现，总的miss次数在330多，离最优情况仍有较大距离。之后通过对A矩阵和B矩阵的地址输出会发现，A,B矩阵相同i,j位置的元素会映射到Cache的同一个Block中，所以在对角线块的转置过程中会发生严重的conflict miss，从而导致miss次数大幅上升。\n具体的过程可以看下面这张示意图，图中模拟了A,B两个3x3的矩阵，两者相同i,j位置的元素会映射到Cache的同一个Line中。Cache中总共有3个Line，每一个Line保存对应行号的内存，如Line1可以保存A矩阵的第一行3个值，或是B矩阵第一行的三个值。A,B矩阵中的数字代表了对着9个元素的读取顺序，高亮强调的表示出现miss，同时每个Line下面的字母代表了保存的是A还是B中的对应内存。\n最终我们可以发现，因为conflict miss的存在，19个元素的读取过程中发生了总共12次miss。\n为了解决这一问题，在不用新建临时变量的情况下，可以使用在读取每一行时最后读取对角线元素的方法，而这就规避了频繁的conflict miss的出现。在A读完该行元素之后，B在覆盖对应行的cache。最终，整体的miss数减小到了8，较为接近理想的6次miss的情况。\n使用这种方法可以将miss个数控制在300以内，符合题目要求。\n64 x 64 这是整个cache实验最难的部分，需要用到临时变量来存值。\n最优情况 $26464/8=1024$\n解题过程 一开始的解题思路和32x32相似，计算应该使用的块的大小。通过计算可以知道对于64x64的矩阵，读入的过程中会发生16次填满Cache的过程。所以块纵轴方向的大小应该为4，而横轴方向还应该为8，因为一个block可以包含8个int。然而因为是计算矩阵的转置，转置之后从4x8变成了8x4，依旧会在B矩阵处造成多次conflict miss。所以还是选用更小的4作为块的大小。\n经过测试之后，使用4x4块的总miss次数为1651，离1300还有一定的距离，需要进行进一步更细致的优化。因此后续分析具体的过程。\n在后续分析的过程中，首先定义分析的块的大小为8x8，内部分为4个4x4的块进行分析。因为每个block可以保存8个int，所以使用8进行分析更为简单。所以64x64的矩阵被分为64个8x8的矩阵，其中在对角线上的矩阵有8个，不在对角线上的矩阵有56个。下面详细分析每种矩阵的miss数。\n对角线上的矩阵 如下图所示，我们将A和B两个矩阵各自划分为4个小块，每个小块为4x4的矩阵，且每个小块内部不会发生conflict miss。\nStep1:将A1转置到B1，这一步使用我们在32x32问题中用到的技巧（每一行最后访问对角线元素），可以算出总的miss为11.此时Cache中保存的为B矩阵的B内存（B1和B2）。 Step2:将C1转置到B2，这一步总共需要8次miss。 这里有一个小的trick，关于转置完A1之后是应该访问A2还是C1。可以看到，如果访问A2，其转置的结果是D2，C1转置的结果是B2。而经过A1转置B1之后，cache中保存的位B矩阵的B内存，所以选择C1可以减小3次conflic miss，最大程度上利用B内存。\nStep3:对A2和C2重复相同步骤，其步骤和Step1和Step2是完全等价的。 所以针对对角线上的矩阵，其总的miss数为$2*(11+8)=38$. 不在对角线的矩阵\n因为矩阵不在对角线上，所以观察示意图可以发现，A矩阵和B矩阵会被映射到不同的Set上，不会发生conflic miss。只有矩阵A,B内部会发生conflict miss，如A1，A2和C1，C2.\nStep1:将A1转置到B1，主要是每个部分自己的4行数据的读取，总共是4+4=8miss。此时Cache中为A(A1,A2)和B（B1,B2）。 Step2:将C1转置到B2，读取C1的过程中会发生4次conflict miss。 Step3:重复Step1和Step2的过程。 所以针对不在对角线上的矩阵，其总的miss数为$2*(8+4)=24$.\n至此我们可以计算我们理论的miss数：$838+5624=1648$.而离测试数据1651还有3个miss的误差可能是因为除矩阵外的其他内存的存取，这个可以在导出的tracef0文件中进行查看。总体来说是符合当前结果的。\n因为，我们的下一步可以选择优化对角线矩阵或者不在对角线上的矩阵使得我们的结果最终能小于1300miss的要求。考虑到不在对角线上的矩阵个数更多，有56个，因此选择优化不在对角线上的矩阵。其理论上的最小的miss次数是$8+8=16$。如果我们能优化到16，那么最后的miss次数为$1651-(24-16)*56=1203$，就能够符合要求。\n在最优情况下，我们希望A,B,C,D内存中的每行只加载一次。当A1转置为B1时，之前我们接下来选择C1转置为B2，而这时A2的数据还没有被保存，在之后的访问中造成了不必要的miss。为了消除这种情况，我们可以将在A1转置为B1的过程中，将A2的数据先保存在B2处。通过这种方法，我们就能保证对A内存区域只加载一次。之后再进行C1和B2的转换，但在这过程中因为题目中对临时变量个数的限制，我们需要选择合适的方法，在这过程中同样把B2中之前保存的A2数据给填充到D2里。最后进行C2和D2的转换。\n下面是具体的操作步骤\nStep1:将A1转置到B1.按列读取A1中的数据，在第一次加载第一列的时候会发生4次miss。在每次读取的过程中，将A2中对应列的数据保存在临时变量a0,a1,a2,a3中，再保存到B2对应的行上。在完成了A1到B1的转置之后，也完成了A2到B2的数据保存。总共发生了8次miss。 Step2:①和②读取B2的第一行，将其值保存在临时变量a0,a1,a2,a3中。③按列读取C1处的第一列，此时发生4次miss。④将C1处的第一列保存到B2的第一行中。此时B内存的第一行都已经得到了正确的值，可以在之后被替换了。⑤将Cache中的B内存的第一行替换为D内存的第一行，发生1次miss。并且将临时变量a0,a1,a2,a3中的值填充到D1的第一行，完成赋值。⑥重复1-5步骤，完成四行的填充。此时完成了A2到D1，C1到B2的转置。总共发生了$4+1+1+1+1=8$次miss。 Step3:此时Cache中为C内存和D内存，完成最后的C2到D2的转置，此时不会发生miss。 所以此时不在对角线上的块的总的miss次数为理想情况的16次。此时的miss次数为$388+1656=1200$。实际测试结果为1203，符合理论情况。 61 x 67 因为不规则，所以即使按块进行划分，还是会渐渐出现一个块中的元素属于不同的block的情况。这里主要的算法思路是先大段继续分块，然后剩余的部分使用最简单的转置。\n在做这道题的时候，我主要尝试了不同的block大小，最后发现好像和8有公因数的块大小都能取得较为不错的效果。如8,6,12,16等。而12又比8有着更好的效果，猜测可能是因为cache更大一些，能够解决更多的一个块中的元素属于不同的block的情况。最终我选择了12，它符合总miss数小于2000的要求。\n","permalink":"https://HaveAnApplePie.github.io/posts/tech/cmu15213-cachelab/","summary":"前言 这篇博客主要是关于CMU15-213课程的CacheLab中的Part B实验的个人优化方案介绍。博客中不涉及具体的代码，具体代码请查看该","title":"CMU15213 CacheLab"}]